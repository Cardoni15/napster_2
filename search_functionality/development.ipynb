{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#track_df = pd.read_csv()\n",
    "temp_path = os.getcwd()\n",
    "root_path = temp_path.split('/napster_2')[0]\n",
    "repo_path = '/napster_2/lyric_genius_api/practice_data.csv'\n",
    "practice_data_path = root_path + repo_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt-rock' 'latin' 'country' 'classical' 'hip-hop' 'edm' 'heavy-metal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2QjOHCTQ1Jl3zawyYOpxh6</td>\n",
       "      <td>Sweater Weather</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2K7xn816oNHJZ0aVqdQsha</td>\n",
       "      <td>Softcore</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5E30LdtzQTGqRvNd7l6kG5</td>\n",
       "      <td>Daddy Issues</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2iUmqdfGZcHIhS3b9E9EWq</td>\n",
       "      <td>Everybody Talks</td>\n",
       "      <td>Neon Trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7zwn1eykZtZ5LODrf7c0tS</td>\n",
       "      <td>You Get Me So High</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>1XgpK29CGGjZnxPYkiRbh4</td>\n",
       "      <td>Hey DJ</td>\n",
       "      <td>CNCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>5q2MjTDby29ZOEigCVV28a</td>\n",
       "      <td>In My Hood</td>\n",
       "      <td>South Park Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>0XpMTExp5q4nLZZZ3msDGn</td>\n",
       "      <td>La Funka</td>\n",
       "      <td>Ozuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>0ulsRBiciReng91DhfVT9D</td>\n",
       "      <td>Bebé</td>\n",
       "      <td>Ozuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>4zK05ecddIq3vfd08Aqi8y</td>\n",
       "      <td>La Vida Es Así</td>\n",
       "      <td>Ivy Queen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  spotify_id          track_name         artist_name\n",
       "0     2QjOHCTQ1Jl3zawyYOpxh6     Sweater Weather   The Neighbourhood\n",
       "1     2K7xn816oNHJZ0aVqdQsha            Softcore   The Neighbourhood\n",
       "2     5E30LdtzQTGqRvNd7l6kG5        Daddy Issues   The Neighbourhood\n",
       "3     2iUmqdfGZcHIhS3b9E9EWq     Everybody Talks          Neon Trees\n",
       "4     7zwn1eykZtZ5LODrf7c0tS  You Get Me So High   The Neighbourhood\n",
       "...                      ...                 ...                 ...\n",
       "7045  1XgpK29CGGjZnxPYkiRbh4              Hey DJ                CNCO\n",
       "7046  5q2MjTDby29ZOEigCVV28a          In My Hood  South Park Mexican\n",
       "7047  0XpMTExp5q4nLZZZ3msDGn            La Funka               Ozuna\n",
       "7048  0ulsRBiciReng91DhfVT9D                Bebé               Ozuna\n",
       "7049  4zK05ecddIq3vfd08Aqi8y      La Vida Es Así           Ivy Queen\n",
       "\n",
       "[7050 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df = pd.read_csv(practice_data_path)\n",
    "print(track_df.genre.unique())\n",
    "rel_columns = ['track_id', 'track_name_x', 'artist_name_x']\n",
    "track_df = track_df[rel_columns]\n",
    "track_df.rename(columns={'track_id': 'spotify_id',\n",
    "                        'track_name_x': 'track_name',\n",
    "                        'artist_name_x': 'artist_name'\n",
    "})\n",
    "#track_df.sample(30, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps for Rocchio Feedback Filter\n",
    "# PROCESS 1 convert the raw lyrics into the concept space.\n",
    "# 1. Create a TFIDF vectorizer\n",
    "# 2. Create a document term matrix using TFIDF vec fit_transform using the raw lyrics. [I think there is an option to lemmatize here]\n",
    "# 3. Complete latent semantic indexing using TruncatedSVD(num components = num comncepts, specifiy the random state)\n",
    "# 4. Fit the document term matrix using TruncatedSVD.fit_transform. THESE ARE YOUR VECTORS FOR SIMILARITY SCORING\n",
    "\n",
    "# PROCESS 2 convert the query into a vector\n",
    "# 1. Convert querry into a raw string\n",
    "# 2. Use the TFIDF vectorizer above to transform the querry\n",
    "# 3. Use the LSI object above to convert the querry into the concept space.\n",
    "\n",
    "# PROCESS 3 execute the search\n",
    "# 1. Find the cosine similarity between the querry and all lyrics\n",
    "# 2. Sort the tracks by similarity\n",
    "# 3. Return the top N tracks to the user.\n",
    "\n",
    "# PROCESS 4 Rochhio Feedback Filtering\n",
    "# 1. Group user feeback by love, no answer, dislike\n",
    "# 2. Calculate the mean for each group\n",
    "# 3. Apply alpha, beta, gamma, and phi to:\n",
    "#       Original search, loves, hates, nuetral\n",
    "# 4. Update the lyric search querry vector and return new results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Parameters\n",
    "# minimum document frequency\n",
    "min_df = 10\n",
    "num_concepts = 100\n",
    "# step 1 import old lyrical data into a dataframe.\n",
    "lyric_df = pd.read_csv(practice_data_path)\n",
    "lyric_df = lyric_df[lyric_df['genre'] != 'latin']\n",
    "lyric_df = lyric_df[['track_name_x', 'artist_name_x', 'track_id','lyric_raw']]\n",
    "lyric_df.rename(columns={\n",
    "    'track_name_x': 'track_name',\n",
    "    'artist_name_x': 'artist_name'\n",
    "}, inplace=True)\n",
    "lyric_df = lyric_df.dropna()\n",
    "# replace new line character\n",
    "lyric_df['lyric_raw'].replace('\\n', ' ',regex=True, inplace=True)\n",
    "# remove embed text from lyric genius API\n",
    "lyric_df['lyric_raw'].replace('[0-9]{1,3}Embed', '', regex=True, inplace=True)\n",
    "# create vectorizer object\n",
    "vecObj = TfidfVectorizer(tokenizer=str.split, min_df=min_df)\n",
    "# fit the TFIDF vectorizer\n",
    "docTermMat = vecObj.fit_transform(lyric_df['lyric_raw'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsiObj = TruncatedSVD(n_components=num_concepts, random_state=42)\n",
    "docVecs = lsiObj.fit_transform(docTermMat)\n",
    "# create a dataframe where the track id is the index the docVecs are the rows.\n",
    "track_vec_dict = defaultdict(list)\n",
    "track_ids = lyric_df['track_id'].values\n",
    "track_vec_dict = {track_ids[i]: docVecs[i] for i in range(len(track_ids))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 convert the query into a vector in the concept space\n",
    "user_query = 'Jealousy, turning saints into the sea Swimming through sick lullabies Choking on your alibis'\n",
    "# vectorize\n",
    "userVec = vecObj.transform([user_query])\n",
    "# convert query vec into the concept space\n",
    "userLsi = lsiObj.transform(userVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 execute search using cosine similarity\n",
    "# 1. Find the cosine similarity between the query and all lyrics\n",
    "# 2. Sort the tracks by similarity\n",
    "# 3. Return the top N tracks to the user.\n",
    "\n",
    "# calculate cosine similarity between every track and the lyric provided.\n",
    "simVals = cosine_similarity(docVecs, userLsi)\n",
    "# create a track name, track id, artist name, similarity dataframe\n",
    "lyric_df['similarity'] = simVals\n",
    "\n",
    "# this step is important, \n",
    "# the lyrics df is officially out of sync now, \n",
    "# the indexes need to be sorted again OR two copies need to be maintained\n",
    "sim_df = lyric_df.sort_values(by='similarity', ascending=False)\n",
    "user_playlist = sim_df.head(30)[['track_name', 'artist_name', 'track_id']]\n",
    "# initialize a feedback column and set every row to 0.\n",
    "user_playlist['feedback'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate user input here\n",
    "feedback = [np.random.randint(0,3) for i in range(len(user_playlist))]\n",
    "user_playlist['feedback'] = feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS 4 Rochhio Feedback Filtering\n",
    "# 1. Group user feeback by love, nuetral, dislike\n",
    "# 2. Calculate the mean for each group\n",
    "# 3. Apply alpha, beta, gamma, and phi to:\n",
    "#       Original search, loves, hates, nuetral\n",
    "# 4. Update the lyric search querry vector and return new results!\n",
    "\n",
    "# tuning parameters\n",
    "# original querry gets no penalty\n",
    "alpha = 1.0\n",
    "# loved songs get a beta positive weight.\n",
    "beta = 0.75\n",
    "# disliked songs get a gamma negative weight\n",
    "gamma = 0.25\n",
    "# nuetral songs get a phi positive weight\n",
    "phi = 0.5\n",
    "\n",
    "# create a mean vector dict for all 3 states\n",
    "meanVectDict = defaultdict(list)\n",
    "\n",
    "# iterate through the three states nuetral[0], dislike[1], love[2]\n",
    "for i in range(3):\n",
    "    temp_tracks = user_playlist[user_playlist['feedback']==i]\n",
    "    if len(temp_tracks) > 0:\n",
    "        # this means that tracks with this sentiment exist.\n",
    "        # we can go get the track vectors from the track_vec_dict\n",
    "        tempVecs = [track_vec_dict[vec] for vec in temp_tracks['track_id']]\n",
    "        # next we need to calculate the mean vector for this segment\n",
    "        meanVec = np.mean(tempVecs, axis=0)\n",
    "        # add this mean to the mean vect dict. The key is the state.\n",
    "        meanVectDict[i] = meanVec\n",
    "    else:\n",
    "        # if there are no tracks in this state, set its mean to 0\n",
    "        meanVectDict[i] = 0\n",
    "\n",
    "# calcualte the new query vector by summing all of the mean vectors together\n",
    "newQueryVec = alpha*userLsi + beta * meanVectDict[2] - gamma * meanVectDict[1] + phi * meanVectDict[0]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 convert the notebook into functions and create a loop!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

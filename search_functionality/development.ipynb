{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#track_df = pd.read_csv()\n",
    "temp_path = os.getcwd()\n",
    "root_path = temp_path.split('/napster_2')[0]\n",
    "repo_path = '/napster_2/lyric_genius_api/practice_data.csv'\n",
    "practice_data_path = root_path + repo_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt-rock' 'latin' 'country' 'classical' 'hip-hop' 'edm' 'heavy-metal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2QjOHCTQ1Jl3zawyYOpxh6</td>\n",
       "      <td>Sweater Weather</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2K7xn816oNHJZ0aVqdQsha</td>\n",
       "      <td>Softcore</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5E30LdtzQTGqRvNd7l6kG5</td>\n",
       "      <td>Daddy Issues</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2iUmqdfGZcHIhS3b9E9EWq</td>\n",
       "      <td>Everybody Talks</td>\n",
       "      <td>Neon Trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7zwn1eykZtZ5LODrf7c0tS</td>\n",
       "      <td>You Get Me So High</td>\n",
       "      <td>The Neighbourhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>1XgpK29CGGjZnxPYkiRbh4</td>\n",
       "      <td>Hey DJ</td>\n",
       "      <td>CNCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>5q2MjTDby29ZOEigCVV28a</td>\n",
       "      <td>In My Hood</td>\n",
       "      <td>South Park Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>0XpMTExp5q4nLZZZ3msDGn</td>\n",
       "      <td>La Funka</td>\n",
       "      <td>Ozuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>0ulsRBiciReng91DhfVT9D</td>\n",
       "      <td>Bebé</td>\n",
       "      <td>Ozuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>4zK05ecddIq3vfd08Aqi8y</td>\n",
       "      <td>La Vida Es Así</td>\n",
       "      <td>Ivy Queen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  spotify_id          track_name         artist_name\n",
       "0     2QjOHCTQ1Jl3zawyYOpxh6     Sweater Weather   The Neighbourhood\n",
       "1     2K7xn816oNHJZ0aVqdQsha            Softcore   The Neighbourhood\n",
       "2     5E30LdtzQTGqRvNd7l6kG5        Daddy Issues   The Neighbourhood\n",
       "3     2iUmqdfGZcHIhS3b9E9EWq     Everybody Talks          Neon Trees\n",
       "4     7zwn1eykZtZ5LODrf7c0tS  You Get Me So High   The Neighbourhood\n",
       "...                      ...                 ...                 ...\n",
       "7045  1XgpK29CGGjZnxPYkiRbh4              Hey DJ                CNCO\n",
       "7046  5q2MjTDby29ZOEigCVV28a          In My Hood  South Park Mexican\n",
       "7047  0XpMTExp5q4nLZZZ3msDGn            La Funka               Ozuna\n",
       "7048  0ulsRBiciReng91DhfVT9D                Bebé               Ozuna\n",
       "7049  4zK05ecddIq3vfd08Aqi8y      La Vida Es Así           Ivy Queen\n",
       "\n",
       "[7050 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df = pd.read_csv(practice_data_path)\n",
    "print(track_df.genre.unique())\n",
    "rel_columns = ['track_id', 'track_name_x', 'artist_name_x']\n",
    "track_df = track_df[rel_columns]\n",
    "track_df.rename(columns={'track_id': 'spotify_id',\n",
    "                        'track_name_x': 'track_name',\n",
    "                        'artist_name_x': 'artist_name'\n",
    "})\n",
    "#track_df.sample(30, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps for Rocchio Feedback Filter\n",
    "# PROCESS 1 convert the raw lyrics into the concept space.\n",
    "# 1. Create a TFIDF vectorizer\n",
    "# 2. Create a document term matrix using TFIDF vec fit_transform using the raw lyrics. [I think there is an option to lemmatize here]\n",
    "# 3. Complete latent semantic indexing using TruncatedSVD(num components = num comncepts, specifiy the random state)\n",
    "# 4. Fit the document term matrix using TruncatedSVD.fit_transform. THESE ARE YOUR VECTORS FOR SIMILARITY SCORING\n",
    "\n",
    "# PROCESS 2 convert the query into a vector\n",
    "# 1. Convert querry into a raw string\n",
    "# 2. Use the TFIDF vectorizer above to transform the querry\n",
    "# 3. Use the LSI object above to convert the querry into the concept space.\n",
    "\n",
    "# PROCESS 3 execute the search\n",
    "# 1. Find the cosine similarity between the querry and all lyrics\n",
    "# 2. Sort the tracks by similarity\n",
    "# 3. Return the top N tracks to the user.\n",
    "\n",
    "# PROCESS 4 Rochhio Feedback Filtering\n",
    "# 1. Group user feeback by love, no answer, dislike\n",
    "# 2. Calculate the mean for each group\n",
    "# 3. Apply alpha, beta, gamma, and phi to:\n",
    "#       Original search, loves, hates, nuetral\n",
    "# 4. Update the lyric search querry vector and return new results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Parameters\n",
    "# minimum document frequency\n",
    "min_df = 10\n",
    "num_concepts = 100\n",
    "# step 1 import old lyrical data into a dataframe.\n",
    "lyric_df = pd.read_csv(practice_data_path)\n",
    "# drop latin songs to avoid negatively impacting performance using 2 languages\n",
    "lyric_df = lyric_df[lyric_df['genre'] != 'latin']\n",
    "lyric_df = lyric_df[['track_name_x', 'artist_name_x', 'track_id','lyric_raw']]\n",
    "lyric_df.rename(columns={\n",
    "    'track_name_x': 'track_name',\n",
    "    'artist_name_x': 'artist_name'\n",
    "}, inplace=True)\n",
    "lyric_df = lyric_df.dropna()\n",
    "# replace new line character\n",
    "lyric_df['lyric_raw'].replace('\\n', ' ',regex=True, inplace=True)\n",
    "# remove embed text from lyric genius API\n",
    "lyric_df['lyric_raw'].replace('[0-9]{1,3}Embed', '', regex=True, inplace=True)\n",
    "# create vectorizer object\n",
    "vecObj = TfidfVectorizer(tokenizer=str.split, min_df=min_df)\n",
    "# fit the TFIDF vectorizer\n",
    "docTermMat = vecObj.fit_transform(lyric_df['lyric_raw'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsiObj = TruncatedSVD(n_components=num_concepts, random_state=42)\n",
    "docVecs = lsiObj.fit_transform(docTermMat)\n",
    "# create a dataframe where the track id is the index the docVecs are the rows.\n",
    "track_vec_dict = defaultdict(list)\n",
    "track_ids = lyric_df['track_id'].values\n",
    "track_vec_dict = {track_ids[i]: docVecs[i] for i in range(len(track_ids))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 convert the query into a vector in the concept space\n",
    "user_query = 'Jealousy, turning saints into the sea Swimming through sick lullabies Choking on your alibis'\n",
    "# vectorize\n",
    "userVec = vecObj.transform([user_query])\n",
    "# convert query vec into the concept space\n",
    "userLsi = lsiObj.transform(userVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 execute search using cosine similarity\n",
    "# 1. Find the cosine similarity between the query and all lyrics\n",
    "# 2. Sort the tracks by similarity\n",
    "# 3. Return the top N tracks to the user.\n",
    "\n",
    "# calculate cosine similarity between every track and the lyric provided.\n",
    "simVals = cosine_similarity(docVecs, userLsi)\n",
    "# create a track name, track id, artist name, similarity dataframe\n",
    "lyric_df['similarity'] = simVals\n",
    "\n",
    "# this step is important, \n",
    "# the lyrics df is officially out of sync now, \n",
    "# the indexes need to be sorted again OR two copies need to be maintained\n",
    "sim_df = lyric_df.sort_values(by='similarity', ascending=False)\n",
    "user_playlist = sim_df.head(30)[['track_name', 'artist_name', 'track_id']]\n",
    "# initialize a feedback column and set every row to 0.\n",
    "user_playlist['feedback'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate user input here\n",
    "feedback = [np.random.randint(0,3) for i in range(len(user_playlist))]\n",
    "user_playlist['feedback'] = feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS 4 Rochhio Feedback Filtering\n",
    "# 1. Group user feeback by love, nuetral, dislike\n",
    "# 2. Calculate the mean for each group\n",
    "# 3. Apply alpha, beta, gamma, and phi to:\n",
    "#       Original search, loves, hates, nuetral\n",
    "# 4. Update the lyric search querry vector and return new results!\n",
    "\n",
    "# tuning parameters\n",
    "# original querry gets no penalty\n",
    "alpha = 1.0\n",
    "# loved songs get a beta positive weight.\n",
    "beta = 0.75\n",
    "# disliked songs get a gamma negative weight\n",
    "gamma = 0.25\n",
    "# nuetral songs get a phi positive weight\n",
    "phi = 0.5\n",
    "\n",
    "# create a mean vector dict for all 3 states\n",
    "meanVectDict = defaultdict(list)\n",
    "\n",
    "# iterate through the three states nuetral[0], dislike[1], love[2]\n",
    "for i in range(3):\n",
    "    temp_tracks = user_playlist[user_playlist['feedback']==i]\n",
    "    if len(temp_tracks) > 0:\n",
    "        # this means that tracks with this sentiment exist.\n",
    "        # we can go get the track vectors from the track_vec_dict\n",
    "        tempVecs = [track_vec_dict[vec] for vec in temp_tracks['track_id']]\n",
    "        # next we need to calculate the mean vector for this segment\n",
    "        meanVec = np.mean(tempVecs, axis=0)\n",
    "        # add this mean to the mean vect dict. The key is the state.\n",
    "        meanVectDict[i] = meanVec\n",
    "    else:\n",
    "        # if there are no tracks in this state, set its mean to 0\n",
    "        meanVectDict[i] = 0\n",
    "\n",
    "# calcualte the new query vector by summing all of the mean vectors together\n",
    "newQueryVec = alpha*userLsi + beta * meanVectDict[2] - gamma * meanVectDict[1] + phi * meanVectDict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5 convert the notebook into functions.\n",
    "def load_lyrics_data():\n",
    "    \"\"\"\n",
    "    return a dataframe with cleaned lyrics\n",
    "    \"\"\"\n",
    "    temp_path = os.getcwd()\n",
    "    root_path = temp_path.split('/napster_2')[0]\n",
    "    repo_path = '/napster_2/lyric_genius_api/practice_data.csv'\n",
    "    data_path = root_path + repo_path\n",
    "    # step 1 import old lyrical data into a dataframe.\n",
    "    lyric_df = pd.read_csv(data_path)\n",
    "    # drop latin songs to avoid negatively impacting performance using 2 languages\n",
    "    lyric_df = lyric_df[lyric_df['genre'] != 'latin']\n",
    "    lyric_df = lyric_df[['track_name_x', 'artist_name_x', 'track_id','lyric_raw']]\n",
    "    lyric_df.rename(columns={\n",
    "        'track_name_x': 'track_name',\n",
    "        'artist_name_x': 'artist_name'\n",
    "    }, inplace=True)\n",
    "    lyric_df = lyric_df.dropna()\n",
    "    # replace new line character\n",
    "    lyric_df['lyric_raw'].replace('\\n', ' ',regex=True, inplace=True)\n",
    "    # remove embed text from lyric genius API\n",
    "    lyric_df['lyric_raw'].replace('[0-9]{1,3}Embed', '', regex=True, inplace=True)\n",
    "    return lyric_df\n",
    "\n",
    "def create_lyric_tfidf(lyric_df, min_df):\n",
    "    \"\"\" \n",
    "    Create a tfidf vectorizer for the track lyrics\n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(tokenizer=str.split, min_df=min_df)\n",
    "    # fit the TFIDF vectorizer\n",
    "    tfidf.fit(lyric_df['lyric_raw'])\n",
    "    return tfidf\n",
    "\n",
    "def lsi_lyrics(lyric_df, tfidf, num_concepts):\n",
    "    \"\"\"\n",
    "    fit an LSI object using the lyrics\n",
    "    \"\"\"\n",
    "    lyricTermMat = tfidf.transform(lyric_df['lyric_raw'])\n",
    "    lsiObj = TruncatedSVD(n_components=num_concepts, random_state=15)\n",
    "    lsiObj.fit(lyricTermMat)\n",
    "    return lsiObj\n",
    "\n",
    "def create_lyric_vecs(lyric_df, lsiObj, tfidf):\n",
    "    \"\"\" \n",
    "    generate the lyric vectors in the concept space\n",
    "    \"\"\"\n",
    "    lyricTermMat = tfidf.transform(lyric_df['lyric_raw'])\n",
    "    lyric_vecs = lsiObj.transform(lyricTermMat)\n",
    "    return lyric_vecs\n",
    "\n",
    "def create_lyric_dictionary(lyric_df, lyric_vecs):\n",
    "    \"\"\" \n",
    "    input a lyric dataframe and lsi lyric vectors\n",
    "    return a dictionary where the track id is the key\n",
    "    the vector is the value\n",
    "    \"\"\"\n",
    "    # create a dataframe where the track id is the index the docVecs are the rows.\n",
    "    track_vec_dict = defaultdict(list)\n",
    "    track_ids = lyric_df['track_id'].values\n",
    "    track_vec_dict = {track_ids[i]: lyric_vecs[i] for i in range(len(track_ids))}\n",
    "    return track_vec_dict\n",
    "\n",
    "def lsi_on_query(lsiObj, user_query, tfidf):\n",
    "    \"\"\" \n",
    "    Transform the user search string into the concept space\n",
    "    \"\"\"\n",
    "    userVec = tfidf.transform([user_query])\n",
    "    # convert query vec into the concept space\n",
    "    userLsi = lsiObj.transform(userVec)\n",
    "    return userLsi\n",
    "\n",
    "def retreive_30_tracks(lyric_df, userLsi, lyric_vecs):\n",
    "    \"\"\" \n",
    "    calculate cosine similarity between lyrics and user query\n",
    "    return the top 30 in a dataframe.\n",
    "    \"\"\"\n",
    "    # calculate cosine similarity between every track and the lyric provided.\n",
    "    simVals = cosine_similarity(lyric_vecs, userLsi)\n",
    "    # create a track name, track id, artist name, similarity dataframe\n",
    "    lyric_df['similarity'] = simVals\n",
    "    user_playlist = lyric_df.sort_values(by='similarity', ascending=False)\n",
    "    user_playlist = user_playlist.head(30)[['track_name', 'artist_name', 'track_id']]\n",
    "    # initialize a feedback column and set every row to 0.\n",
    "    user_playlist['feedback'] = 0\n",
    "    return user_playlist\n",
    "\n",
    "def simulate_user_input(user_playlist):\n",
    "    \"\"\" \n",
    "    Simulate user input assign 0,1,2 to user feedback\n",
    "    0 = nuetral\n",
    "    1 = dislike\n",
    "    2 = love\n",
    "    \"\"\"\n",
    "    feedback = [np.random.randint(0,3) for i in range(len(user_playlist))]\n",
    "    user_playlist['feedback'] = feedback\n",
    "    return user_playlist\n",
    "\n",
    "def rocchio_feedback(alpha, beta, gamma, phi, user_playlist, track_vec_dict):\n",
    "    \"\"\" \n",
    "    Rochhio Feedback Filtering\n",
    "    1. Group user feeback by love, nuetral, dislike\n",
    "    2. Calculate the mean for each group\n",
    "    3. Apply alpha, beta, gamma, and phi to:\n",
    "           Original search, loves, hates, nuetral\n",
    "    4. Update the lyric search querry vector and return new results!\n",
    "    return an updated query vector to improve search results\n",
    "    \"\"\"\n",
    "    # create a mean vector dict for all 3 states\n",
    "    meanVectDict = defaultdict(list)\n",
    "    # iterate through the three states nuetral[0], dislike[1], love[2]\n",
    "    for i in range(3):\n",
    "        temp_tracks = user_playlist[user_playlist['feedback']==i]\n",
    "        if len(temp_tracks) > 0:\n",
    "            # this means that tracks with this sentiment exist.\n",
    "            # we can go get the track vectors from the track_vec_dict\n",
    "            tempVecs = [track_vec_dict[vec] for vec in temp_tracks['track_id']]\n",
    "            # next we need to calculate the mean vector for this segment\n",
    "            meanVec = np.mean(tempVecs, axis=0)\n",
    "            # add this mean to the mean vect dict. The key is the state.\n",
    "            meanVectDict[i] = meanVec\n",
    "        else:\n",
    "            # if there are no tracks in this state, set its mean to 0\n",
    "            meanVectDict[i] = 0\n",
    "    # calcualte the new query vector by summing all of the mean vectors together\n",
    "    newQueryVec = alpha*userLsi + beta * meanVectDict[2] - gamma * meanVectDict[1] + phi * meanVectDict[0]\n",
    "    return newQueryVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cardoni/Library/Python/3.8/lib/python/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6 integrate all functions into a loop\n",
    "user_query =  'Jealousy, turning saints into the sea Swimming through sick lullabies Choking on your alibis'\n",
    "# load in lyrics dataframe\n",
    "lyric_df = load_lyrics_data()\n",
    "# create a tfidf vectorizer object\n",
    "tfidf = create_lyric_tfidf(lyric_df, 10)\n",
    "# create a latent semantic indexing object\n",
    "lsiObj = lsi_lyrics(lyric_df, tfidf, 100)\n",
    "# convert the lyrics into content vectors\n",
    "lyric_vecs = create_lyric_vecs(lyric_df, lsiObj, tfidf)\n",
    "# create a dictionary mapping track id to content vector\n",
    "track_vec_dict = create_lyric_dictionary(lyric_df, lyric_vecs)\n",
    "# convert a user string query into the concept space\n",
    "userLsi = lsi_on_query(lsiObj, user_query, tfidf)\n",
    "# create a user playlist and return a dataframe\n",
    "user_playlist = retreive_30_tracks(lyric_df, userLsi, lyric_vecs)\n",
    "# simulate user input while we are not connected to the GUI\n",
    "user_playlist = simulate_user_input(user_playlist)\n",
    "# Apply rocchio feedback filter to generate a better query\n",
    "rocchioSearch = rocchio_feedback(1.0, 0.75, 0.25, 0.5, user_playlist, track_vec_dict)\n",
    "# generate a new user playlist with the updated search\n",
    "user_playlist = retreive_30_tracks(lyric_df, rocchioSearch, lyric_vecs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
